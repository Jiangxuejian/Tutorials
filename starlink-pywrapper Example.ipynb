{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starlink and Python: the starlink-pywrapper package.\n",
    "\n",
    "\n",
    "Starlink-pywrapper provides wrappers around the normal Starlink packages like KAPPA, CUPID etc, to make them easier to call from python, and so you don't have to use shell escapes in your arguments. It requires you to have a functioning Starlink Software Suite install on your computer and to know where Starlink is located, but it does not require you to run the Starlink setup scripts. It also packages up various parts of the help so that they are easily available within your python session.\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "This package depends on the `starlink-pyhds` package (which  is a low level package that allows you to read and write `.sdf` files within Python), and which itself depends on the `numpy` package. These packages should normally instaleld with pypi.\n",
    "\n",
    "This package should work in either Python 2.7 or Python 3.5+.\n",
    "\n",
    "## This notebook:\n",
    "1. setting up the package\n",
    "1. Getting help with the package\n",
    "1. Basic Usage\n",
    "1. Running an ORAC-DR Reduction\n",
    "1. Running many ORAC-DR reductions\n",
    "\n",
    "\n",
    "\n",
    "## Setting up the package.\n",
    "\n",
    "First of all, you need to import the package and let it know where Starlink is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find Starlink: please run change_starpath(\"/path/to/star\")\n"
     ]
    }
   ],
   "source": [
    "from starlink import wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This warning message just means that I hadn't set the `$STARLINK_DIR` environmental variable, so the wrapper doesn't know where to find your installation of Starlink. If you had set that variable before you started Python, the wrapper would automatically use that Starlink installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can manually tell the wrapper where Starlink is with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wrapper.change_starpath('/Users/sarah/star-2017A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ever can't remember which Starlink you are using, look at the `wrapper.starpath`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sarah/star-2017A\n"
     ]
    }
   ],
   "source": [
    "print(wrapper.starpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences from standard Starlink\n",
    "This wrapper attempts to allow pythonic calling of Starlink commands, and is designed primarily for scripting. Therefore it has altered or removed some of the features you may be used to if you are experienced at using the commandline Starlink.\n",
    "\n",
    "1. Using this wrapper, Starlink will **not** remember your previously used values for any of the commands.\n",
    "1. If using xwindows as a graphic display for the plotting commands (`linplot`, `display` etc), you **have** to give the device name (using `gdset` will usually not work).\n",
    "1. For keyword arguments, you have to give the full argument name (abbreviating it will not work)\n",
    "1. Starlink will not prompt you if you forget a keyword argument that is needed, the command will instead fail with an error.\n",
    "\n",
    "\n",
    "### Unexpected `features` if you're used to Python\n",
    "The way in which Starlink calls commands is very different from Starlink. The package attempts to neatly divide all the possible arguments for a command into `required` positional arguments and `optional` keyword arguments. However, often you will **have** to give some of the keyword arguments to run the command successfully. Hopefully the documentation on each command should make this clear. Occasionally there will be a required argument that you don't actually need -- normally you can safely give any value to these without causing any problems.\n",
    "\n",
    "It is possible that the automatic generator script that creates the documentation and call signatures for the commands could have a bug such that the resulting starlink-pywrapper command cannot work succesfully. If you run into any issue like this, please let me know so we can fix this (s.graves AT eaobservatory.org).\n",
    "\n",
    "## Basic usage of the commands.\n",
    "\n",
    "The commands should be called like normal python functions. E.g, to call the `KAPPA` `stats` function you would do (replace this with a path to a file on your own machine):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    comp    DATA\n",
      "kurtosis    1147.2814951588975\n",
      "   total    3818111.2175611774\n",
      " minimum    -800.1018996019743\n",
      "skewness    29.107865318223343\n",
      "  numpix    58081\n",
      "  maxwcs    18:53:18.867, 1:14:54.30, 0.00085\n",
      "  minpos    [-102, -10, 1]\n",
      "  numbad    18133\n",
      "  maxpos    [0, 0, 1]\n",
      "     ndf    ../Starlink_Analysis/scuba2_map.sdf\n",
      "    mean    95.57703057878183\n",
      "maxcoord    [-1.3381681735838045, 0.021788981266010584, 0.00085]\n",
      " numgood    39948\n",
      "   sigma    887.2211091888624\n",
      "   order    False\n",
      "mincoord    [-1.3361896752346525, 0.02159501271504439, 0.00085]\n",
      "  minwcs    18:53:46.073, 1:14:14.29, 0.00085\n",
      " maximum    48378.649881284786\n"
     ]
    }
   ],
   "source": [
    "from starlink import kappa\n",
    "file =  '../Starlink_Analysis/scuba2_map.sdf'\n",
    "statsvals = kappa.stats(file)\n",
    "print(statsvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commands are easily called as `<package>.<commandname>`\n",
    "\n",
    "Required (positional) arguments can be given either by position, or you can use the full name and pass the value as if it was a keyword, like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Starlink_Analysis/scuba2_map.sdf\n"
     ]
    }
   ],
   "source": [
    "statsvals = kappa.stats(ndf=file)\n",
    "print(statsvals.ndf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional arguments are shown in the inline help, and are passed like normal Python keyword arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    comp    ERROR\n",
      "kurtosis    26.029946463873603\n",
      "   total    1640087.3019753105\n",
      " minimum    10.638659143775554\n",
      "skewness    3.9059048292368095\n",
      "  numpix    58081\n",
      "  maxwcs    18:53:22.334, 1:23:02.30, 0.00085\n",
      "  minpos    [-3, 23, 1]\n",
      "  numbad    18133\n",
      "  maxpos    [-13, 122, 1]\n",
      "     ndf    ../Starlink_Analysis/scuba2_map.sdf\n",
      "    mean    41.05555477058478\n",
      "maxcoord    [-1.337915996605891, 0.024154866836891307, 0.00085]\n",
      "  median    21.865963058563082\n",
      " numgood    39948\n",
      "   sigma    50.65975753759802\n",
      "   order    True\n",
      "mincoord    [-1.33810998137446, 0.022235009763934978, 0.00085]\n",
      "  minwcs    18:53:19.667, 1:16:26.30, 0.00085\n",
      " maximum    1157.3041341557991\n"
     ]
    }
   ],
   "source": [
    "statsvals = kappa.stats(ndf=file, order=True, comp='ERROR')\n",
    "print(statsvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returned values\n",
    "\n",
    "The return object is a `namedtuple` object (see https://docs.python.org/3/library/collections.html#collections.namedtuple ). The values in the object are automatically populated from the values written into the `$ADAM_DIR/<commandname>.sdf` parameter file. If you have used the `parget` command in Starlink to programmatically get return values this should be familiar.\n",
    "\n",
    "You access fields in the output value as attributes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.865963058563082 <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(statsvals.median, type(statsvals.median))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the full list of fields programmatically, you can look at the `returnval._fields` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('comp', 'kurtosis', 'total', 'minimum', 'skewness', 'numpix', 'maxwcs', 'minpos', 'numbad', 'maxpos', 'ndf', 'mean', 'maxcoord', 'median', 'numgood', 'sigma', 'order', 'mincoord', 'minwcs', 'maximum')\n"
     ]
    }
   ],
   "source": [
    "print(statsvals._fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This return value lets you use the calculated values of Starlink commands in your scripts.\n",
    "\n",
    "Commands that primarly produce an output file rather than calculate values may not write anything very interesting to the return value; it may just repeat the values of the parameters you set (and the default paramters you didn't give) from the command line call. For example, if we look at the output of  CONVERTs NDF2FITS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       out    !scuba2_map.fits\n",
      "      comp    A\n",
      "    native    False\n",
      "  checksum    True\n",
      "   proexts    False\n",
      "    duplex    False\n",
      "    prohis    True\n",
      " container    False\n",
      "  encoding    Auto\n",
      "    bitpix    0\n",
      "  allowtab    True\n",
      "provenance    None\n",
      "       in_    ../Starlink_Analysis/scuba2_map.sdf\n",
      "   profits    True\n",
      "False True\n"
     ]
    }
   ],
   "source": [
    "from starlink import convert\n",
    "\n",
    "a = convert.ndf2fits(in_=file, out='!scuba2_map.fits')\n",
    "print(a)\n",
    "\n",
    "import os\n",
    "print(os.path.isfile(a.out), os.path.isfile('scuba2_map.fits'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately the 'out' value is exactly as you described it in the function call -- it does not represent the newly written file name itself. Here, the function call had a prepended exclamation mark, which allows you to overwrite a FITS file of the same name. The produced file on disk does not have that exclamation mark, but this is not shown to you in the `a.out` value.\n",
    "\n",
    "You can also see that the parameter name 'in' from Starlink has been translated to `in_` for the Python wrapper; this is because `in` is a Python reserved name, so it has had an underscore attached to its name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting help with the package\n",
    "\n",
    "This package attempts to bundle some of the most useful help with the package. You can see a short summary of a command and its python call signature and allowed keywords with the normal Python `help` function. These are intended to be of use when you are running interactive sessions, either in the terminal or in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function add in module starlink.kappa:\n",
      "\n",
      "add(in1, in2, out, **kwargs)\n",
      "    Adds two NDF data structures.\n",
      "    \n",
      "    Runs the command: $KAPPA_DIR/add .\n",
      "    \n",
      "    Arguments\n",
      "    ---------\n",
      "    in1 : str,filename\n",
      "        First input NDF\n",
      "    \n",
      "    in2 : str,filename\n",
      "        Second input NDF\n",
      "    \n",
      "    out : str,filename\n",
      "        Output NDF\n",
      "    \n",
      "    \n",
      "    Keyword Arguments\n",
      "    -----------------\n",
      "    title : str\n",
      "        Title for output NDF [!]\n",
      "    \n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    See http://www.starlink.ac.uk/cgi-bin/htxserver/sun95.htx/sun95.html?xref_ADD\n",
      "    for full documentation of this command in the latest Starlink release\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from starlink import kappa, cupid\n",
    "help(kappa.add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the help it should include a URL taking you to the full Starlink documentation of this command (not specific to using Python to call it.) This will include a lot more detail on the command and its options.\n",
    "\n",
    "You can also see the module help -- this will include the version of starlink these wrappers were generated for, as well as the help (same as above) on all the commands in the module. Warning: this is very long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module starlink.cupid in starlink:\n",
      "\n",
      "NAME\n",
      "    starlink.cupid - Runs commands from the Starlink CUPID package.\n",
      "\n",
      "DESCRIPTION\n",
      "    Autogenerated from the starlink .hlp and .ifl files,\n",
      "    by starlink-pywrapper/helperscripts/generate_functions.py.\n",
      "    \n",
      "    Starlink version: 2017A\n",
      "    bfdc8534a17c406c59302030ed1c1ae1a1223bd1 (2017-07-28 09:12:59)\n",
      "\n",
      "FUNCTIONS\n",
      "    clumpinfo(ndf, **kwargs)\n",
      "        Obtain information about one or more previously identified clumps.\n",
      "        \n",
      "        Runs the command: $CUPID_DIR/clumpinfo .\n",
      "        \n",
      "        Arguments\n",
      "        ---------\n",
      "        ndf : str,filename\n",
      "            Input NDF containing clump identifications\n",
      "        \n",
      "        \n",
      "        Keyword Arguments\n",
      "        -----------------\n",
      "        clumps : str\n",
      "            The indices of the clumps to use [ALL]\n",
      "        \n",
      "        quiet : bool\n",
      "            Supress screen output? [FALSE]\n",
      "        \n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        flbnd : List[float]\n",
      "        \n",
      "        fubnd : List[float]\n",
      "        \n",
      "        lbound : List[int]\n",
      "        \n",
      "        nclumps : int\n",
      "        \n",
      "        ubound : List[int]\n",
      "        \n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See http://www.starlink.ac.uk/cgi-bin/htxserver/sun255.htx/sun255.html?xref_CLUMPINFO\n",
      "        for full documentation of this command in the latest Starlink release\n",
      "    \n",
      "    cupidhelp(*args, **kwargs)\n",
      "        Display information about CUPID.\n",
      "        \n",
      "        Runs the command: $CUPID_DIR/cupidhelp .\n",
      "        \n",
      "        Keyword Arguments\n",
      "        -----------------\n",
      "        topic : str\n",
      "            Help topic [\" \"]\n",
      "        \n",
      "        subtopic : str\n",
      "            Help subtopic [\" \"]\n",
      "        \n",
      "        subsubtopic : str\n",
      "            Help subsubtopic [\" \"]\n",
      "        \n",
      "        subsubsubtopic : str\n",
      "            Help subsubsubtopic [\" \"]\n",
      "        \n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See http://www.starlink.ac.uk/cgi-bin/htxserver/sun255.htx/sun255.html?xref_CUPIDHELP\n",
      "        for full documentation of this command in the latest Starlink release\n",
      "    \n",
      "    extractclumps(mask, data, out, outcat, **kwargs)\n",
      "        Extract previously identified clumps of emission from an NDF.\n",
      "        \n",
      "        Runs the command: $CUPID_DIR/extractclumps .\n",
      "        \n",
      "        Arguments\n",
      "        ---------\n",
      "        mask : str,filename\n",
      "            Input mask NDF\n",
      "        \n",
      "        data : str,filename\n",
      "            Input data NDF\n",
      "        \n",
      "        out : str,filename\n",
      "            Output mask NDF\n",
      "        \n",
      "        outcat : str\n",
      "            Output catalogue\n",
      "        \n",
      "        \n",
      "        Keyword Arguments\n",
      "        -----------------\n",
      "        backoff : bool\n",
      "            Remove background when finding clump sizes? [TRUE]\n",
      "        \n",
      "        deconv : bool\n",
      "            Correct clump parameters for beam smoothing? [TRUE]\n",
      "        \n",
      "        fwhmbeam : float\n",
      "            Spatial beam width in pixels [dyn.]\n",
      "        \n",
      "        jsacat : str\n",
      "            Output JSA-style catalogue [!]\n",
      "        \n",
      "        logfile : str\n",
      "            Name of output log file [!]\n",
      "        \n",
      "        shape : str\n",
      "            Spatial clump shape in output catalogue [dyn.]\n",
      "        \n",
      "        velores : float\n",
      "            Velocity resolution in channels [dyn.]\n",
      "        \n",
      "        wcspar : bool\n",
      "            Use WCS units in the output catalogue? [dyn.]\n",
      "        \n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        nclumps : int\n",
      "        \n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See http://www.starlink.ac.uk/cgi-bin/htxserver/sun255.htx/sun255.html?xref_EXTRACTCLUMPS\n",
      "        for full documentation of this command in the latest Starlink release\n",
      "    \n",
      "    findback(in_, out, **kwargs)\n",
      "        Estimate the background in an NDF by removing small scale structure.\n",
      "        \n",
      "        Runs the command: $CUPID_DIR/findback .\n",
      "        \n",
      "        Arguments\n",
      "        ---------\n",
      "        `in_` : str,filename\n",
      "            Input NDF\n",
      "        \n",
      "        out : str,filename\n",
      "            Output NDF\n",
      "        \n",
      "        \n",
      "        Keyword Arguments\n",
      "        -----------------\n",
      "        box : List[int]\n",
      "            Filter dimensions, in pixels [9]\n",
      "        \n",
      "        msg_filter : str\n",
      "            Information level [NORM]\n",
      "        \n",
      "        newalg : bool\n",
      "            Use experimental algorithm variations? [FALSE]\n",
      "        \n",
      "        rms : float\n",
      "            RMS noise level\n",
      "        \n",
      "        sub : bool\n",
      "            Subtract background from input data? [FALSE]\n",
      "        \n",
      "        wlim : float\n",
      "            Weight limit for good output pixels [0.3]\n",
      "        \n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See http://www.starlink.ac.uk/cgi-bin/htxserver/sun255.htx/sun255.html?xref_FINDBACK\n",
      "        for full documentation of this command in the latest Starlink release\n",
      "    \n",
      "    findclumps(in_, out, **kwargs)\n",
      "        Identify clumps of emission within a 1, 2 or 3 dimensional NDF.\n",
      "        \n",
      "        Runs the command: $CUPID_DIR/findclumps .\n",
      "        \n",
      "        Arguments\n",
      "        ---------\n",
      "        `in_` : str,filename\n",
      "            Input NDF\n",
      "        \n",
      "        out : str,filename\n",
      "            Output NDF\n",
      "        \n",
      "        \n",
      "        Keyword Arguments\n",
      "        -----------------\n",
      "        outcat : str\n",
      "            Output KAPPA-style catalogue [!]\n",
      "        \n",
      "        method : str\n",
      "            Clump identification algorithm [current value]\n",
      "        \n",
      "        backoff : bool\n",
      "            Remove background when finding clump sizes? [dyn.]\n",
      "        \n",
      "        config : str\n",
      "            Algorithm tuning parameters [current value]\n",
      "        \n",
      "        deconv : bool\n",
      "            Correct clump parameters for beam smoothing? [TRUE]\n",
      "        \n",
      "        jsacat : str\n",
      "            Output JSA-style catalogue [!]\n",
      "        \n",
      "        logfile : str\n",
      "            Name of output log file [!]\n",
      "        \n",
      "        msg_filter : str\n",
      "            Information level [NORM]\n",
      "        \n",
      "        perspectrum : bool\n",
      "            Process spectra independently of neighbouring spectra? [FALSE]\n",
      "        \n",
      "        qout : str,filename\n",
      "            Copy of input NDF with Quality mask [!]\n",
      "        \n",
      "        repconf : bool\n",
      "            Report supplied configuration? [current value]\n",
      "        \n",
      "        rms : float\n",
      "            RMS noise level\n",
      "        \n",
      "        shape : str\n",
      "            Spatial clump shape in output catalogue [dyn.]\n",
      "        \n",
      "        wcspar : bool\n",
      "            Use WCS units in the output catalogue? [dyn.]\n",
      "        \n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        nclumps : int\n",
      "        \n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See http://www.starlink.ac.uk/cgi-bin/htxserver/sun255.htx/sun255.html?xref_FINDCLUMPS\n",
      "        for full documentation of this command in the latest Starlink release\n",
      "    \n",
      "    makeclumps(out, outcat, **kwargs)\n",
      "        Create simulated data containing clumps and noise.\n",
      "        \n",
      "        Runs the command: $CUPID_DIR/makeclumps .\n",
      "        \n",
      "        Arguments\n",
      "        ---------\n",
      "        out : str,filename\n",
      "            Output NDF\n",
      "        \n",
      "        outcat : str\n",
      "            Output catalogue\n",
      "        \n",
      "        \n",
      "        Keyword Arguments\n",
      "        -----------------\n",
      "        angle : List[float]\n",
      "            Mean and width of spatial position angles in degs [current value]\n",
      "        \n",
      "        beamfwhm : float\n",
      "            Spatial FWHM of instrument beam in pixels [current value]\n",
      "        \n",
      "        deconv : bool\n",
      "            Correct clump parameters for beam smoothing? [TRUE]\n",
      "        \n",
      "        fwhm1 : List[float]\n",
      "            Mean and width of FWHMs on pixel axis 1 in pixels [current value]\n",
      "        \n",
      "        fwhm2 : List[float]\n",
      "            Mean and width of FWHMs on pixel axis 2 in pixels [current value]\n",
      "        \n",
      "        fwhm3 : List[float]\n",
      "            Mean and width of FWHMs on pixel axis 3 in pixels [current value]\n",
      "        \n",
      "        grid : int\n",
      "            Margin to place round outside of regular grid [!]\n",
      "        \n",
      "        lbnd : List[int]\n",
      "            Lower pixel bounds of output array [1,1]\n",
      "        \n",
      "        like : str,filename\n",
      "            An NDF to define the output WCS [!]\n",
      "        \n",
      "        model : str,filename\n",
      "            Output NDF without noise\n",
      "        \n",
      "        nclump : List[int]\n",
      "            Number of clumps to create [50]\n",
      "        \n",
      "        pardist : str\n",
      "            Parameter distribution [current value]\n",
      "        \n",
      "        peak : List[float]\n",
      "            Mean and width of clump peak values [current value]\n",
      "        \n",
      "        precat : bool\n",
      "            Create catalogue before instrumental smoothing is applied? [FALSE]\n",
      "        \n",
      "        rms : float\n",
      "            RMS noise to add to data [current value]\n",
      "        \n",
      "        shape : str\n",
      "            Spatial clump shape in output catalogue [\"None\"]\n",
      "        \n",
      "        trunc : float\n",
      "            Truncation level for clumps [current value]\n",
      "        \n",
      "        ubnd : List[int]\n",
      "            Upper pixel bounds of output array [200,200]\n",
      "        \n",
      "        velfwhm : float\n",
      "            FWHM of velocity resolution in pixels [current value]\n",
      "        \n",
      "        vgrad1 : List[float]\n",
      "            Mean and width of vel. gradient on axis 1 [current value]\n",
      "        \n",
      "        vgrad2 : List[float]\n",
      "            Mean and width of vel. gradient on axis 2 [current value]\n",
      "        \n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See http://www.starlink.ac.uk/cgi-bin/htxserver/sun255.htx/sun255.html?xref_MAKECLUMPS\n",
      "        for full documentation of this command in the latest Starlink release\n",
      "    \n",
      "    outlineclump(*args, **kwargs)\n",
      "        Draw an outline around a 2-dimensional clump identified by CUPID.\n",
      "        \n",
      "        Runs the command: $CUPID_DIR/outlineclump.csh .\n",
      "        \n",
      "        Keyword Arguments\n",
      "        -----------------\n",
      "        index : \n",
      "               The integer index or indices of the clumps to be identified.\n",
      "           For multiple indices supply a comma-separated list, using\n",
      "           hyphens to express ranges.  For example \"2,4-6,9\" would draw\n",
      "           the outlines of clumps with indices 2, 4, 5, 6, and 9.\n",
      "        \n",
      "        ndf : \n",
      "               The name of the NDF containing the clump information. This NDF\n",
      "           should have been created using the CUPID:FINDCLUMPS or\n",
      "           CUPID:EXTRACTCLUMPS command. The clump cut-out images contained in\n",
      "           the CUPID extension of this NDF will be used to define the outline\n",
      "           of the clump.\n",
      "        \n",
      "        style : \n",
      "               A group of attribute settings describing the plotting style to\n",
      "           use for the outline.\n",
      "        \n",
      "           A comma-separated list of strings should be given in which each\n",
      "           string is either an attribute setting, or the name of a text\n",
      "           file preceded by an up-arrow character \"^\".  Such text files\n",
      "           should contain further comma-separated lists which will be read\n",
      "           and interpreted in the same manner.  Attribute settings are\n",
      "           applied in the order in which they occur within the list, with\n",
      "           later settings overriding any earlier settings given for the\n",
      "           same attribute.\n",
      "        \n",
      "           Each individual attribute setting should be of the form:\n",
      "        \n",
      "              <name>=<value>\n",
      "        \n",
      "           where <name> is the name of a plotting attribute, and <value>\n",
      "           is the value to assign to the attribute. Default values will be\n",
      "           used for any unspecified attributes.  All attributes will be\n",
      "           defaulted if a null value (!) is supplied.  See section\n",
      "           \"Plotting Attributes\" in SUN/95 for a description of the\n",
      "           available attributes.  Any unrecognised attributes are ignored\n",
      "           (no error is reported).\n",
      "        \n",
      "           The appearance of the clump outline is controlled by the attributes\n",
      "           Colour(Curves), Width(Curves), etc (the synonym Contours may be\n",
      "           used in place of Curves). The contour appearance established in\n",
      "           this way may be modified using parameters PENS, PENROT and\n",
      "           DASHED. [current value]\n",
      "        \n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See http://www.starlink.ac.uk/cgi-bin/htxserver/sun255.htx/sun255.html?xref_OUTLINECLUMP\n",
      "        for full documentation of this command in the latest Starlink release\n",
      "\n",
      "FILE\n",
      "    /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/starlink/cupid.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cupid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make it easier to see what is available in a module, the package contains a `starhelp` command in the `utilities` subpackage. If you call this on a module this will show you a listing of all the commands available in that module, along with a short one line description of what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clumpinfo     :     Obtain information about one or more previously identified clumps.\n",
      "cupidhelp     :     Display information about CUPID.\n",
      "extractclumps :     Extract previously identified clumps of emission from an NDF.\n",
      "findback      :     Estimate the background in an NDF by removing small scale structure.\n",
      "findclumps    :     Identify clumps of emission within a 1, 2 or 3 dimensional NDF.\n",
      "makeclumps    :     Create simulated data containing clumps and noise.\n",
      "outlineclump  :     Draw an outline around a 2-dimensional clump identified by CUPID."
     ]
    }
   ],
   "source": [
    "from starlink.utilities import starhelp\n",
    "starhelp(cupid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you call `starhelp` on a command, it will show you the **full** documentation of this Starlink command (not specific to this python wrapper) in .rst format. It will probably be better to look at the normal online Starlink documentation instead (linked at the end of the normal `help` or `?` on a command)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ADD\n",
      "===\n",
      "\n",
      "\n",
      "Purpose\n",
      "~~~~~~~\n",
      "Adds two NDF data structures\n",
      "\n",
      "\n",
      "Description\n",
      "~~~~~~~~~~~\n",
      "The routine adds two NDF data structures pixel-by-pixel to produce a\n",
      "new NDF.\n",
      "\n",
      "\n",
      "Usage\n",
      "~~~~~\n",
      "\n",
      "\n",
      "::\n",
      "\n",
      "    \n",
      "       add in1 in2 out\n",
      "       \n",
      "\n",
      "\n",
      "\n",
      "ADAM parameters\n",
      "~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "\n",
      "IN1 = NDF (Read)\n",
      "````````````````\n",
      "First NDF to be added.\n",
      "\n",
      "\n",
      "\n",
      "IN2 = NDF (Read)\n",
      "````````````````\n",
      "Second NDF to be added.\n",
      "\n",
      "\n",
      "\n",
      "OUT = NDF (Write)\n",
      "`````````````````\n",
      "Output NDF to contain the sum of the two input NDFs.\n",
      "\n",
      "\n",
      "\n",
      "TITLE = LITERAL (Read)\n",
      "``````````````````````\n",
      "Value for the title of the output NDF. A null value will cause the\n",
      "title of the NDF supplied for parameter IN1 to be used instead. [!]\n",
      "\n",
      "\n",
      "\n",
      "Examples\n",
      "~~~~~~~~\n",
      "add a b c\n",
      "This adds the NDF called b to the NDF called a, to make the NDF called\n",
      "c. NDF c inherits its title from a.\n",
      "add out=c in1=a in2=b title=\"Co-added image\"\n",
      "This adds the NDF called b to the NDF called a, to make the NDF called\n",
      "c. NDF c has the title \"Co-added image\".\n",
      "\n",
      "\n",
      "\n",
      "Notes\n",
      "~~~~~\n",
      "\n",
      "\n",
      "+ The output NDF contains the simple sum of the input NDFs.\n",
      "Inparticularly, the input variances are not used as weights. For a\n",
      "weighted co-addition, use CCDPACK:MAKEMOS.\n",
      "+ If the two input NDFs have different pixel-index bounds, then they\n",
      "  will be trimmed to match before being added. An error will result if\n",
      "  they have no pixels in common.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Related Applications\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "KAPPA: CADD, CDIV, CMULT, CSUB, DIV, MATHS, MULT, SUB.\n",
      "\n",
      "\n",
      "Copyright\n",
      "~~~~~~~~~\n",
      "Copyright (C) 1990, 1992 Science & Engineering Research Council.\n",
      "Copyright (C) 1995, 1998, 2004 Central Laboratory of the Research\n",
      "Councils. Copyright (C) 2007, 2012 Science & Technology Facilities\n",
      "Council. All Rights Reserved.\n",
      "\n",
      "\n",
      "Licence\n",
      "~~~~~~~\n",
      "This program is free software; you can redistribute it and/or modify\n",
      "it under the terms of the GNU General Public License as published by\n",
      "the Free Software Foundation; either Version 2 of the License, or (at\n",
      "your option) any later version.\n",
      "This program is distributed in the hope that it will be useful, but\n",
      "WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n",
      "General Public License for more details.\n",
      "You should have received a copy of the GNU General Public License\n",
      "along with this program; if not, write to the Free Software\n",
      "Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA\n",
      "02110-1301, USA.\n",
      "\n",
      "\n",
      "Implementation Status\n",
      "~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "+ This routine correctly processes the WCS, AXIS, DATA, QUALITY,\n",
      "LABEL, TITLE, HISTORY, and VARIANCE components of an NDF data\n",
      "structure and propagates all extensions.\n",
      "+ The UNITS component is propagated only if it has the same value in\n",
      "both input NDFs.\n",
      "+ Processing of bad pixels and automatic quality masking are\n",
      "supported.\n",
      "+ All non-complex numeric data types can be handled.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "starhelp(kappa.add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More advanced features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've previously only examined the output of Starlink commands by reading or grepping the output written to the terminal, hopefully the return values shown here will be useful. Generally, you should not need to grep the string output of a Starlink command.\n",
    "\n",
    "\n",
    "However, particularly while you are developing your script you may still sometimes want to see with the *normal* output, so this module does provide a means of doing that. The simplest way is to turn the standard python logging module into DEBUG mode. When you do that, the module will write both the full Starlink command it is running (useful if you run into problems) as well as the normal terminal output you would see if you ran this on the command line. For example, if you turn on DEBUG logging and run the `kappa.stats` command you will see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:starlink.wrapper:['/Users/sarah/star-2017A/bin/kappa/stats', '../Starlink_Analysis/scuba2_map.sdf', 'comp=ERROR', 'order=True']\n",
      "DEBUG:starlink.wrapper:\n",
      "   Pixel statistics for the NDF structure /Users/sarah/SeoulUsersMeeting/Tutorials/../Starlink_Analysis/scuba2_map\n",
      "\n",
      "      Title                     : G34.3\n",
      "      NDF array analysed        : ERROR\n",
      "\n",
      "         Pixel sum              : 1640087.30197531\n",
      "         Pixel mean             : 41.0555547705848\n",
      "         Standard deviation     : 50.659757537598\n",
      "         Skewness               : 3.90590482923681\n",
      "         Kurtosis               : 26.0299464638736\n",
      "         Minimum pixel value    : 10.6386591437756\n",
      "            At pixel            : (-3, 23, 1)\n",
      "            Co-ordinate         : (18:53:19.667, 1:16:26.30, 0.00085)\n",
      "         Maximum pixel value    : 1157.3041341558\n",
      "            At pixel            : (-13, 122, 1)\n",
      "            Co-ordinate         : (18:53:22.334, 1:23:02.30, 0.00085)\n",
      "         Pixel median           : 21.8659630585631\n",
      "         Total number of pixels : 58081\n",
      "         Number of pixels used  : 39948 (68.8%)\n",
      "         No. of pixels excluded : 18133 (31.2%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.root.setLevel(logging.DEBUG)\n",
    "\n",
    "statsvals = kappa.stats(ndf=file, order=True, comp='ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn this back to only showing INFO level logging information, you would run (in a jupyter notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.root.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a normal Python script or interactive session (not a jupyter notebook) you would normally run\n",
    "```python\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel('DEBUG')\n",
    "```\n",
    "\n",
    "#### Accessing the Standard Output as a string\n",
    "Sometimes you may want to get the stdoutput as a string. You shouldn't normally need this, but if you do then pass the keyword argument `returnstdout=True` to any of the Starlink commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Pixel statistics for the NDF structure /Users/sarah/SeoulUsersMeeting/Tutorials/../Starlink_Analysis/scuba2_map\n",
      "\n",
      "      Title                     : G34.3\n",
      "      NDF array analysed        : ERROR\n",
      "\n",
      "         Pixel sum              : 1640087.30197531\n",
      "         Pixel mean             : 41.0555547705848\n",
      "         Standard deviation     : 50.659757537598\n",
      "         Skewness               : 3.90590482923681\n",
      "         Kurtosis               : 26.0299464638736\n",
      "         Minimum pixel value    : 10.6386591437756\n",
      "            At pixel            : (-3, 23, 1)\n",
      "            Co-ordinate         : (18:53:19.667, 1:16:26.30, 0.00085)\n",
      "         Maximum pixel value    : 1157.3041341558\n",
      "            At pixel            : (-13, 122, 1)\n",
      "            Co-ordinate         : (18:53:22.334, 1:23:02.30, 0.00085)\n",
      "         Pixel median           : 21.8659630585631\n",
      "         Total number of pixels : 58081\n",
      "         Number of pixels used  : 39948 (68.8%)\n",
      "         No. of pixels excluded : 18133 (31.2%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "statsvals, stdout = kappa.stats(ndf=file, order=True, comp='ERROR', returnstdout=True)\n",
    "print(stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This causes the command to return a tuple of the normal returned object and the Starlink terminal output as a string.\n",
    "\n",
    "\n",
    "### Shell Escapes\n",
    "Unlike the commandline, this python wrapper doesn't go through a shell, so you do not have to use shell escapes around string values. For example, when providing an NDF section to only show a 6 by 6 pixel square of your map you would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    comp    ERROR\n",
      "kurtosis    -0.8029823301673149\n",
      "   total    2044.2819842583647\n",
      " minimum    15.635780592588478\n",
      "skewness    0.8710338530851028\n",
      "  numpix    36\n",
      "  maxwcs    18:53:18.600, 1:14:54.30, 0.00085\n",
      "  minpos    [5, 5]\n",
      "  numbad    0\n",
      "  maxpos    [1, 0]\n",
      "     ndf    ../Starlink_Analysis/scuba2_map.sdf(0:5,0:5)\n",
      "    mean    56.78561067384343\n",
      "maxcoord    [-1.3381875707353537, 0.02178898127010817, 0.00085]\n",
      " numgood    36\n",
      "   sigma    43.44768072049565\n",
      "   order    False\n",
      "mincoord    [-1.338265159505499, 0.02188594394031615, 0.00085]\n",
      "  minwcs    18:53:17.533, 1:15:14.30, 0.00085\n",
      " maximum    145.2239807802179\n",
      "../Starlink_Analysis/scuba2_map.sdf(0:5,0:5)\n"
     ]
    }
   ],
   "source": [
    "# No need to use shell escapes! E.g., if you want to pass an ndfsection you can do\n",
    "section = '(0:5,0:5)'\n",
    "statsvals = kappa.stats(ndf=file+section, comp='ERROR')\n",
    "print(statsvals)\n",
    "print(statsvals.ndf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note however that you still can't include spaces in your NDF section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Starlink error occured during command:\n/Users/sarah/star-2017A/bin/kappa/stats ('../Starlink_Analysis/scuba2_map.sdf(0:5, 0:5)',)\n stdout and stderr are appended below.\n!! GRP1_PAREL: Un-matched delimiters '()' found in\n!     '../Starlink_Analysis/scuba2_map.sdf(0:5,'.\n!  GRP_GRPEX: Unable to read names from group expression\n!     ../Starlink_Analysis/scuba2_map.sdf(0:5,\n!  Error obtaining a group of existing NDFs using group expression\n!     \"../Starlink_Analysis/scuba2_map.sdf(0:5,\"\n!  Unable to associate a group of NDFs with parameter NDF.\n!  STATS: Error computing simple statistics for an NDF's pixels.\n!  Application exit status GRP__INVEL, Invalid element syntax given\n!  ../Starlink_Analysis/scuba2_map.sdf(0:5, 0:5) comp=ERROR\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-69c6731b4b73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(0:5, 0:5)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstatsvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkappa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ERROR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/starlink/kappa.py\u001b[0m in \u001b[0;36mstats\u001b[0;34m(ndf, **kwargs)\u001b[0m\n\u001b[1;32m   9005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9006\u001b[0m     \"\"\"\n\u001b[0;32m-> 9007\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarcomm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"$KAPPA_DIR/stats\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stats\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/starlink/wrapper.py\u001b[0m in \u001b[0;36mstarcomm\u001b[0;34m(command, commandname, *args, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} does not exist'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madamfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Starlink error occured during command:\n/Users/sarah/star-2017A/bin/kappa/stats ('../Starlink_Analysis/scuba2_map.sdf(0:5, 0:5)',)\n stdout and stderr are appended below.\n!! GRP1_PAREL: Un-matched delimiters '()' found in\n!     '../Starlink_Analysis/scuba2_map.sdf(0:5,'.\n!  GRP_GRPEX: Unable to read names from group expression\n!     ../Starlink_Analysis/scuba2_map.sdf(0:5,\n!  Error obtaining a group of existing NDFs using group expression\n!     \"../Starlink_Analysis/scuba2_map.sdf(0:5,\"\n!  Unable to associate a group of NDFs with parameter NDF.\n!  STATS: Error computing simple statistics for an NDF's pixels.\n!  Application exit status GRP__INVEL, Invalid element syntax given\n!  ../Starlink_Analysis/scuba2_map.sdf(0:5, 0:5) comp=ERROR\n\n"
     ]
    }
   ],
   "source": [
    "section = '(0:5, 0:5)'\n",
    "statsvals = kappa.stats(ndf=file+section, comp='ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error handling\n",
    "The above example illustrates error handling. As well as the normal Python traceback seen at the top of the screen, you should also be shown the Starlink command that was run, its arguments, and the actual Starlink-generated error message. In this case, if you read the message you can see that it is trying to evaluate `'Starlink_Analysis/scuba2_map.sdf(0:5,'` as an NDF section, and of course failing. This is because the space we included in the NDF section causes Starlink to break the parameter at that point.\n",
    "\n",
    "You can use normal Python exception handling to deal with these Starlink errors.\n",
    "\n",
    "Currently ORAC-DR calls through `wrapper.oracdr` (see below) don't raise an error when they have problems; instead they produce a return value. This will probably be changed int he next version of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running an ORAC-DR reduction\n",
    "\n",
    "The `starlink.wrapper` module includes a function to help you script ORAC-DR reductions from Python scripts. Although this may seem a little unnecessary (ORAC-DR is itself a script running Starlink commands from Perl), we've found quite a few JCMT users need to script ORAC-DR reductions. Often, people need to tweak some of the configuration options for ORAC-DR, and being able to easily re-run their whole reduction with only one thing changed, or being able to run through a pre-defined matrix of different options (recipes, recipe parameters, or even input data) to compare the outputs is required.\n",
    "\n",
    "Please note that the ORAC-DR implementation is a bit cruder than some other parts -- we're not intending on changing the call signature, but we could conceivably provide more specific, wrapped functions to call specific reduction recipes in the future. Let us know if this sounds like it could be useful!\n",
    "\n",
    "The function to run ORAC-DR is called `oracdr` and is inside the `starlink.wrapper` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function oracdr in module starlink.wrapper:\n",
      "\n",
      "oracdr(instrument, loop='file', dataout=None, datain=None, recipe=None, recpars=None, onegroup=False, rawfiles=None, utdate=None, obslist=None, headeroverride=None, calib=None, verbose=False, debug=False, warn=False)\n",
      "    Run oracdr on a batch of files.\n",
      "    \n",
      "    Arguments\n",
      "    ---------\n",
      "    instrument: str\n",
      "        Name of instrument\n",
      "    \n",
      "    Keyword Arguments\n",
      "    -----------------\n",
      "    \n",
      "    loop: str\n",
      "      'file' or 'list'. determine if input obs are specified as\n",
      "      raw file names/paths or as a list of observation numbers and a\n",
      "      utdate. ['file']\n",
      "    \n",
      "    dataout: str\n",
      "       Location of output data directory; defaults to current dir.\n",
      "    \n",
      "    datain: str\n",
      "       Location of input data; defaults to current dir.\n",
      "    \n",
      "    recipe str:\n",
      "       Name of recipe to run. If None, use recipe from headers.\n",
      "    \n",
      "    recpars str:\n",
      "       Value to pass as a recipe parameter option -- either a filename\n",
      "       or the recpars themselves.\n",
      "    \n",
      "    onegroup: Bool\n",
      "       Force all observations into one processing group.\n",
      "    \n",
      "    rawfiles:  str or list of filenames/paths\n",
      "      If a string, this is a text file giving names of all input\n",
      "      files. If list, then list of all input files as python\n",
      "      list. Files are taken relative to datain, or can be given as\n",
      "      absolute path. Only used if loop='file'\n",
      "    \n",
      "    utdate: int, YYYYMMDD\n",
      "       The utdate of the input data. Only used if loop='list'\n",
      "    \n",
      "    obslist: List(int)\n",
      "      List of input scan numbers. Input file names will be generated\n",
      "      assuming JCMT/UKIRT directory structure, similar to\n",
      "      <datain>/<utdate>/<scannumber>/rawfiles .\n",
      "    \n",
      "    headeroverride: str, filename\n",
      "       File with optional header overrides.\n",
      "    \n",
      "    calib: str\n",
      "       Calibration overrides. Accepts comma separated key=value pairs.\n",
      "    \n",
      "    verbose: bool\n",
      "       Include output from Starlink commands in log/stdout.\n",
      "    \n",
      "    debug: bool\n",
      "       Include debug output in log/stdout.\n",
      "    \n",
      "    warn: bool\n",
      "       Show Perl warning messages.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    \n",
      "    Return value is a named tuple with the following attributes:\n",
      "    \n",
      "     - runlog: name of output logfile.\n",
      "     - outputdir: path of output directory\n",
      "     - datafiles: list of output data files.\n",
      "     - imagefiles: list of output image files.\n",
      "     - logfiles: list of log.* files\n",
      "     - status: int, return code from suprocess.Popen\n",
      "     - pid (int): pid of perl parent process.\n",
      "    \n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This will *not* raise an exception if ORAC-DR ended with an error;\n",
      "    it is up to the calling code to check the status if required.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from starlink import wrapper\n",
    "help(wrapper.oracdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return values from an ORAC-DR run are quite different from other commands in this module: it will give you an object with attributes telling you where the output logfile is (very useful to see what happened), the output directory, lists of data, image and log files produced at the end of the output, the status code and the pid of the Perl process that ran ORAC-DR.\n",
    "\n",
    "#### Differences from the stand-alone ORAC-DR.\n",
    "ORAC-DR was designed to write information to index files when it is run in a specific directory, and read that information back in if it is run in the same directory, allowing it to do things like turn off detectors that it already knows will fail QA etc. Although this behaviour is very powerful and vital for some use cases, it also causes problems when scripting JCMT data, especially when you want to run through a whole series of DRs, changing various DR and QA parameters to see what effect they have etc.\n",
    "\n",
    "I've also seen several people accidentally write over their previous DR runs by changing to a new directory, but forgetting to change the `ORAC_DATAOUT` environmental variable.\n",
    "\n",
    "To avoid this, this wrapper **always** runs ORAC-DR in a new, unique, directory created in the directory specified as `dataout=`. The directory name is returned to the user in the output value. It is up to the user to clear up these output directories if needed. \n",
    "\n",
    "If the original behaviour is needed, a future version of this module could add a keyword argument reverting to the default non-python ORAC-DR behaviour (and defaulting to False).\n",
    "\n",
    "#### Instrument name\n",
    "\n",
    "This has to be provided. The available options are in: `wrapper.JCMTINST`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACSIS', 'SCUBA2_850', 'SCUBA2_450', 'SCUBA', 'JCMTDAS']\n"
     ]
    }
   ],
   "source": [
    "print(wrapper.JCMTINST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods of specifying the input files:\n",
    "\n",
    "Normally you will be providing a list of files. You can provide this by first creating a textfile listing each raw filename on a new line (with either a full path or the path relative the `datain` directory), and then you pass this filename in as a string like `rawfiles='myfile.lis'`. Alternatively, you can pass in a Python list object, where each entry is a string giving the absolute or relative path of a raw file. \n",
    "\n",
    "#### Recipe choice\n",
    "If you want to use a recipe other than the default value set in the `RECIPE` FITS header of your raw data, then you would pass its full name to the `recipe=` keyword argument.\n",
    "\n",
    "\n",
    "### Handling errors\n",
    "\n",
    "Currently (and this may change in the future), this command doesn't raise an exception of ORAC-DR ends with an error. You'll need to manually look at the returned status int, and/or read the log file to see what happened.\n",
    "\n",
    "### Example usage\n",
    "Here is a simple example, where some data files are passed as a Python list to ORAC-DR. The instrument is set, and it then runs the chosen recipe ('REDUCE_SCAN') on that data. If you are running this in a jupyter notebook, then normal ORAC-DR terminal output is shown in the terminal where you started the jupyter process (sorry!).\n",
    "\n",
    "This example uses the raw files provided by the SCUBA-2  Tutorial, and to speed things up, is only using the 's8a' subarray. It takes 2 minutes to run on a 2013 Mac laptop with 4GB of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "rawdatapath = '../SCUBA2_tutorial/raw/'\n",
    "\n",
    "\n",
    "files = glob.glob(os.path.join(rawdatapath, 's8a20120501_00068*.sdf'))\n",
    "print(files)\n",
    "\n",
    "output = wrapper.oracdr('SCUBA2_850', loop='file', dataout='.', \n",
    "                        recipe='REDUCE_SCAN', rawfiles=files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The returned output\n",
    "`output` holds various information about the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output._fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`output.runlog`: This gives the full path location of the logfile for this ORAC-DR run. This file is inside the ORAC working directory for this call of `wrapper.oracdr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(output.runlog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`output.outdir`: This gives the full path of the temporary working directory where all the output files are written: the ORAC_DATA_OUT location. This is unique for each call of `wrapper.oracdr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(output.outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`output.datafiles`: This gives the full list of `.sdf` files produced by this ORAC-DR call. Please note that it will sometimes include files that should ahve been cleaned out by ORAC-DR: e.g. t3270.sdf or similar. These can be safely ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output.datafiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`output.imagefiles`: The full list of `.png` files (normally preview images) produced by this ORAC-DR call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output.imagefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`output.logfiles`: Any `log.*` files produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output.logfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read these in with the astropy table module. Unfortunately the 'log.group' default files require different means of reading in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "groupfile = [i for i in output.logfiles if i.endswith('log.group')][0]\n",
    "otherlogs = [i for i in output.logfiles if not i.endswith('log.group')]\n",
    "group = Table.read(groupfile, format='ascii.commented_header')\n",
    "print(groupfile)\n",
    "print(group, '\\n')\n",
    "for i in otherlogs:\n",
    "    print(i)\n",
    "    print(Table.read(i, format='ascii.commented_header', header_start=3),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`output.status`: <int>, the return status of the ORAC-DR run. If there were no errors, then this will be 0. If it is not 0, please check the `output.runlog` file to see what went wrong.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(output.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`output.pid`: the process id of the ORAC-DR run (not normally needed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(output.pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running many ORAC-DR reductions, with varying options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First get the list of files:\n",
    "\n",
    "Assume you have a single file listing the utdate/observation combo you want to get, and a path that contains the downloaded data from CADC.\n",
    "\n",
    "Assemble a Python list of raw data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write our observation dates and obsnums to a file.\n",
    "# Normally you would have many, here we only have one observation.\n",
    "f = open('observation.lis' , 'w')\n",
    "f.write('20120501, 68\\n')\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "#patternmatch: this is a string that can be formatted with a date and year\n",
    "# ({} indicate something which will be formatted), and will then match SCUBA-2 file names.\n",
    "# {:d} This will be formated with the YYYYMMDD as an integer\n",
    "# {:05d} Format the observation number, padded to 5 digits with zeros.\n",
    "# [0-9] Match any digit from 0 to 9\n",
    "s2850_rawfile_match = 's8a{:d}_{:05d}_[0-9][0-9][0-9][0-9].sdf'\n",
    "\n",
    "\n",
    "# If you have a more powerful computer, match all the files instead of only subarray by uncommenting the line below:\n",
    "#s2850_rawfile_match = 's8[a-d]{:d}_{:05d}_[0-9][0-9][0-9][0-9].sdf'\n",
    "\n",
    "path='../SCUBA2_tutorial/raw/'\n",
    "outputfiles = []\n",
    "f = open('observation.lis', 'r')\n",
    "\n",
    "for line in f:\n",
    "    utdate, obsnum = line.strip().split(', ')\n",
    "    utdate = int(utdate)\n",
    "    obsnum = int(obsnum)\n",
    "    filematch = s2850_rawfile_match.format(utdate, obsnum)\n",
    "    outputfiles += glob.glob(os.path.join(path, filematch))\n",
    "f.close()\n",
    "\n",
    "outputfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now going to run those observations through ORAC-DR. However, we're going to imagine that these are new observations and we aren't quite sure yet how we want to reduce them. We're going to iterate through both some recipes and some pixel sizes. This will show you how to give recpars as a string: you can also write them to a Recipe Parameter text file (which can have different options for  different sources/ frequencies / etc, allowing you to use a single file.)\n",
    "\n",
    "**Be warned, this runs ORAC-DR on the two observations above 6 times, so it will take a few minutes to run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = ['REDUCE_SCAN', 'REDUCE_SCAN_EXTENDED_SOURCES']\n",
    "pixelsizes = [4.0,6.0,8.0]\n",
    "\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "outputs = []\n",
    "for recipe in recipes:\n",
    "    for pixsize in pixelsizes:\n",
    "        print('RECIPE %s, Pixel size %d'%(recipe, pixsize))\n",
    "        outputdir = 'testing-{}-pixsize-{}'.format(recipe, str(pixsize).replace('.','_'))\n",
    "        if not os.path.isdir(outputdir):\n",
    "            os.mkdir(outputdir)\n",
    "        recpar_string = 'MAKEMAP_PIXSIZE={}'.format(pixsize)\n",
    "        output = wrapper.oracdr('SCUBA2_850', loop='file', rawfiles=files, onegroup=True,\n",
    "                                dataout=outputdir, recipe=recipe, recpars=recpar_string)\n",
    "        outputs.append(output)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the files are stored inside various ORACTEMP directories, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs[0].outdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to keep the output files, we might move them out of the ORACworking* directories and into the normal working directories. (This wrapper puts everything into seperate directories to avoid repeated runs overwriting the same files. )\n",
    "\n",
    "The image files ORAC-DR produces are stored in the outout.imagefiles command, and its fairly easy to grab only group coadds of a specific size with a **conditional list comprehension**; you could also use a for loop if you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imagefiles = [i for i in outputs[0].imagefiles if os.path.split(i)[1].startswith('g') and i.endswith('1024.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then either save the list of images to look at in your chosen image viewing program, or if you are working in a jupyter notebook like here display them as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "images_to_show = []\n",
    "for o in outputs:\n",
    "    imagefiles = [i for i in o.imagefiles if os.path.split(i)[1].startswith('g') and i.endswith('256.png')]\n",
    "    print(imagefiles[0])\n",
    "    display(Image(imagefiles[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A couple of useful extras inside starlink-pywrapper\n",
    "\n",
    "There is a utility function in the `starlink.utilities` module which will read in the FITS headers of an NDF file and convert it into an Astropy `fitsheader` object. This requires the `astropy` package to be installed and available to Python. It is used as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starlink.utilities import get_ndf_fitshdr\n",
    "fitsheader = get_ndf_fitshdr('../Starlink_Analysis/scuba2_map.sdf')\n",
    "fitsheader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picard recipes are also available, either in the same way as ORAC-DR via `wrapper.picard`, or wrapped up for each recipe as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calc_scuba2_avpspec      : Run PICARD'S CALC_SCUBA2_AVPSPEC recipe.\n",
      "calc_scuba2_fcf          : Run PICARD'S CALC_SCUBA2_FCF recipe.\n",
      "calc_scuba2_nefd         : Run PICARD'S CALC_SCUBA2_NEFD recipe.\n",
      "calibrate_scuba2_data    : Run PICARD'S CALIBRATE_SCUBA2_DATA recipe.\n",
      "coadd_jsa_tiles          : Run PICARD'S COADD_JSA_TILES recipe.\n",
      "create_moments_map       : Run PICARD'S CREATE_MOMENTS_MAP recipe.\n",
      "create_png               : Run PICARD'S CREATE_PNG recipe.\n",
      "crop_scuba2_images       : Run PICARD'S CROP_SCUBA2_IMAGES recipe.\n",
      "estimate_image_alignment : Run PICARD'S ESTIMATE_IMAGE_ALIGNMENT recipe.\n",
      "jsa_catalogue            : Run PICARD'S JSA_CATALOGUE recipe.\n",
      "mosaic_jcmt_images       : Run PICARD'S MOSAIC_JCMT_IMAGES recipe.\n",
      "picard_demonstrator      : Run PICARD'S PICARD_DEMONSTRATOR recipe.\n",
      "scuba2_check_cal         : Run PICARD'S SCUBA2_CHECK_CAL recipe.\n",
      "scuba2_check_rms         : Run PICARD'S SCUBA2_CHECK_RMS recipe.\n",
      "scuba2_display_pca       : Run PICARD'S SCUBA2_DISPLAY_PCA recipe.\n",
      "scuba2_jackknife         : Run PICARD'S SCUBA2_JACKKNIFE recipe.\n",
      "scuba2_jackknife_psf     : Run PICARD'S SCUBA2_JACKKNIFE_PSF recipe.\n",
      "scuba2_map_pspec         : Run PICARD'S SCUBA2_MAP_PSPEC recipe.\n",
      "scuba2_mapstats          : Run PICARD'S SCUBA2_MAPSTATS recipe.\n",
      "scuba2_matched_filter    : Run PICARD'S SCUBA2_MATCHED_FILTER recipe.\n",
      "scuba2_photom            : Run PICARD'S SCUBA2_PHOTOM recipe.\n",
      "scuba2_register_images   : Run PICARD'S SCUBA2_REGISTER_IMAGES recipe.\n",
      "scuba2_remove_background : Run PICARD'S SCUBA2_REMOVE_BACKGROUND recipe.\n",
      "scuba2_sassy             : Run PICARD'S SCUBA2_SASSY recipe.\n",
      "stack_jcmt_frames        : Run PICARD'S STACK_JCMT_FRAMES recipe.\n",
      "uncalibrate_scuba2_data  : Run PICARD'S UNCALIBRATE_SCUBA2_DATA recipe.\n",
      "untrim_jsa_tiles         : Run PICARD'S UNTRIM_JSA_TILES recipe."
     ]
    }
   ],
   "source": [
    "from starlink import picard\n",
    "starhelp(picard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
